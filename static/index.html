<script src="https://cdn.jsdelivr.net/npm/pixi.js@6.5.2/dist/browser/pixi.min.js"></script>
<script src="https://cubism.live2d.com/sdk-web/cubismcore/live2dcubismcore.min.js"></script>
<script src="https://cdn.jsdelivr.net/gh/dylanNew/live2d/webgl/Live2D/lib/live2d.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/pixi-live2d-display/dist/index.min.js"></script>

<head>
    <style>
        body {
            background-image: url('./bg/cityscape.jpeg');
            background-size: cover;
            background-position: center;
        }

        .fixed-bottom {
            position: fixed;
            bottom: 0;
            left: 0.5vw;
            right: 0.5vw;
            width: 100%;
            background-color: rgba(33, 33, 33, 0.8);
            color: white;
            text-align: left;
            text-wrap: wrap;
            padding: 10px;
            z-index: 1000;
            /* 确保元素在最前面 */
        }
    </style>
</head>

<body style="position: fixed; bottom: 0;">
    <canvas id="canvas"></canvas>
    <h1 class="fixed-bottom" id="message"></h1>
</body>

<script src="./modelDict.js"></script>
<!-- <script src="./index.js"></script> -->
<script src="./live2d.js"></script>

<script>
    // Initialize the Live2D module with default model
    live2dModule.init().then(() => {
        live2dModule.loadModel(modelDict[0]);
    });
</script>

<script>
    // task queue
    // - store tasks in queue, and run them one by one if there are tasks in the queue
    class TaskQueue {
        constructor() {
            this.queue = [];
            this.running = false;
            this.taskInterval = 3000;
        }

        addTask(task) {
            this.queue.push(task);
            this.runNextTask();
        }

        clearQueue() {
            this.queue = [];
        }

        async runNextTask() {
            if (this.running || this.queue.length === 0) {
                if (this.queue.length === 0) {
                    console.log("Queue is empty");
                }
                return;
            }

            this.running = true;
            const task = this.queue.shift();
            try {
                await task();
            } catch (error) {
                console.error('Task failed', error);
            }
            this.running = false;
            setTimeout(() => this.runNextTask(), this.taskInterval);
            // this.runNextTask();
        }
    }

    // 示例异步任务
    // const asyncTask = (taskName, duration) => async () => {
    //     console.log(`Starting task: ${taskName}`);
    //     await new Promise((resolve) => setTimeout(resolve, duration));
    //     console.log(`Completed task: ${taskName}`);
    // };

    const taskQueue = new TaskQueue();


</script>

<script>
    // browserHost = window.location.hostname;
    // port = window.location.port;

    var wsUrl = "ws://127.0.0.1:8000/live2d-motion-ws";
    // if running on server
    if (window.location.protocol.startsWith("http")) {
        console.log("Running on server")
        wsUrl = "/live2d-motion-ws";
    } else { // if running on local using file://
        console.log("Running on local")
    }

    
    // handle ws
    document.addEventListener("DOMContentLoaded", function () {
        const ws = new WebSocket(wsUrl);
        ws.onopen = function () {
            console.log("Connected to WebSocket " + wsUrl);
        };

        ws.onclose = function () {
            console.log("Disconnected from WebSocket " + wsUrl);
            talk = false;
            taskQueue.clearQueue();
        };

        ws.onmessage = function (event) {
            // console.log("Received message: " + event.data);
            // console.log(event);
            handleMessage(JSON.parse(event.data));
        };
    });


    function handleMessage(message) {
        console.log("Received Request: \n", message)
        switch (message.type) {
            case "full-text":
                document.getElementById("message").textContent = message.text;
                console.log(message)
                console.log("full-text: ", message.text);
            case "control":
                if (message.text === "speaking-start") {
                    if (talk) {
                        console.log("Already talking");
                        return;
                    }
                    talk = true;
                    stupidTalk();
                } else if (message.text === "speaking-stop") {
                    if (!talk) {
                        console.log("Not talking");
                        return;
                    }
                    talk = false;
                }
                break;
            case "expression":
                setExpression(message.text);
                break;

            case "mouth":
                setMouth(Number(message.text));
                break;

            case "audio":
                playAudioLipSync(message.audio, message.volumes, message.slice_length);
                break;

            case "set-model": // not yet implemented
                console.log("set-model: ", message.text);
                live2dModule.init().then(() => {
                    live2dModule.loadModel(message.text);
                });
                break;

            case "listExpressions":
                console.log(listSupportedExpressions());
                break;
            default:
                console.error("Unknown message type: " + message.type);
                console.log(message)
        }
    }






    // set expression of the model2
    // @param {int} expressionIndex - the expression index defined in the emotionMap in modelDict.js
    function setExpression(expressionIndex) {
        expressionIndex = parseInt(expressionIndex);
        model2.internalModel.motionManager.expressionManager.setExpression(expressionIndex);
        console.info(`>> [x] -> Expression set to: (${expressionIndex})`);

        // Reset the expression after 3 seconds
        // setTimeout(() => {
        //     model2.internalModel.motionManager.expressionManager.setExpression(0);
        //     console.info(">> Expression reset");
        // }, 3000);
    }

    // Check if the string contains an expression. If it does, set the expression of the model2.
    // @param {string} str - the string to check
    // 
    function checkStringForExpression(str) {
        console.log("emo map: ", emoMap);
        for (const key of Object.keys(emoMap)) {
            if (str.toLowerCase().includes("[" + key + "]")) {
                console.info(">> [ ] <- add to exec queue: " + key + ", " + emoMap[key]);
                taskQueue.addTask(() => { setExpression(emoMap[key]); });
                taskQueue.addTask(() => { console.log("timing out...") });
                // setExpression(emoMap[key]);
            }
        }
    }

    function listSupportedExpressions() {
        emoMap = model2.internalModel.motionManager.expressionManager.emotionMap;
        console.log(emoMap);
    }



    let talk = false;

    /**
     * Initiates an animation that simulates talking by opening and closing the mouth randomly. This function uses a recursive timeout to continuously toggle the mouth's open state at random intervals, simulating random talking movements.
     */
    function stupidTalk() {
        let isOpen = false; // track if mouth is open

        function toggleMouth() {
            if (!talk) {
                model2.internalModel.coreModel.setParamFloat('PARAM_MOUTH_OPEN_Y', 0.1);
                return;
            }

            if (isOpen) {
                model2.internalModel.coreModel.setParamFloat('PARAM_MOUTH_OPEN_Y', 0.1);
                isOpen = false;
            } else {
                model2.internalModel.coreModel.setParamFloat('PARAM_MOUTH_OPEN_Y', (Math.random() * (0.9 - 0.5) + 0.5));
                isOpen = true;
            }

            setTimeout(toggleMouth, (Math.random() * (0.2 - 0.1) + 0.1) * 1000);
        }

        toggleMouth();
    }

    function setMouth(mouthY) {
        if (typeof model2.internalModel.coreModel.setParameterValueById === 'function') {
            model2.internalModel.coreModel.setParameterValueById('ParamMouthOpenY', mouthY);
        } else {
            model2.internalModel.coreModel.setParamFloat('PARAM_MOUTH_OPEN_Y', mouthY);
        }
        // model2.internalModel.coreModel.setParameterValueById('ParamMouthOpenY', mouthY);
    }



    function playAudioLipSync(audio_base64, volumes, slice_length) {

        const audio = new Audio("data:audio/wav;base64," + audio_base64);
        audio.play();

        let i = 0;
        const interval = setInterval(() => {
            if (i >= volumes.length) {
                clearInterval(interval);
                return;
            }
            setMouth(volumes[i]);
            i++;
        }, slice_length);

    }



</script>